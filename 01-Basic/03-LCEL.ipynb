{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3856a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9c45a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")\n",
    "\n",
    "# LangSmith 추적을 원하지 않을 경우\n",
    "# logging.langsmith(\"CH01-Basic\", set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea70ca9",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿의 활용\n",
    "`PromptTemplate`\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다.\n",
    "- 사용법\n",
    "    - `template` : 템플릿 문자열입니다. 이 문자열 내에서 중괄호 `{}`는 변수를 나타냅니다.\n",
    "    - `input_variables` : 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "</br>\n",
    "\n",
    "`input_variables`\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92735ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f809e58",
   "metadata": {},
   "source": [
    "`from_template()` 메소드를 사용하여 PromptTemplate 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e00918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09ca983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a356ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ea3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb6dc4",
   "metadata": {},
   "source": [
    "### LCEL(LangChain Expression Language) </br>\n",
    "\n",
    "여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합합니다. </br>\n",
    "\n",
    "`chain = prompt | model | output_parser` </br>\n",
    "\n",
    "`|` 기호는 unix 파이프 연산자와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다. </br>\n",
    "\n",
    "이 체인에서 사용자의 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달됩니다. 각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고 있는지 이해할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "716f8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt를 PromptTemplate 객체로 생성합니다. \n",
    "prompt = PromptTemplate.from_template(\"{topic}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b806bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='{topic}에 대해 쉽게 설명해주세요.')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x14b8ae900>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x14b8ae420>, root_client=<openai.OpenAI object at 0x148ff7740>, root_async_client=<openai.AsyncOpenAI object at 0x14abc13a0>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf01111",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "- python 딕셔너리 형태로 입력값을 전달합니다. (키:값)\n",
    "- invoke() 함수 호출 시, 입력값을 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리' 로 설정합니다.\n",
    "input = {\"topic\" : \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# prompt = PromptTemplate.from_template(\"{topic}에 대해 쉽게 설명해주세요.\")\n",
    "# topic을 채워주지 않으면 에러가 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51af5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 원하는 결과를 도출하기 위해 자동으로 가중치를 조정하는 과정입니다. \\n\\n먼저, 학습 데이터를 모델에 입력하고 모델은 입력 데이터를 분석하여 예측을 수행합니다. 예측 결과와 실제 결과를 비교하여 오차를 계산하고, 이 오차를 최소화하기 위해 모델의 가중치를 업데이트합니다.\\n\\n이 과정을 반복하면서 모델은 학습 데이터에 대한 패턴을 습득하고 최적의 가중치를 학습하여 새로운 데이터에 대해 정확한 예측을 할 수 있도록 됩니다. 이러한 과정을 통해 모델은 학습 데이터에 대한 패턴을 추출하고 일반화된 예측을 수행할 수 있게 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 259, 'prompt_tokens': 33, 'total_tokens': 292, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CqH7fMEACaEcXgsp4bK9MW1qOGEKs', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f3f7972b-cc72-41b2-a9f0-af3c660fcd9c-0', usage_metadata={'input_tokens': 33, 'output_tokens': 259, 'total_tokens': 292, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d40ea05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 다양한 데이터를 입력으로 받아 그 데이터 간의 패턴이나 관계를 학습하는 과정을 말합니다. 이를 위해 모델은 수학적인 알고리즘을 사용하여 데이터를 분석하고 특정한 규칙을 찾아내게 됩니다. 이후, 주어진 데이터에 대한 예측이나 분류를 수행할 수 있게 됩니다.\\n\\n모델은 초기에는 무작위로 설정된 가중치를 가지고 데이터를 입력받아 가공하고 예측하게 됩니다. 그리고 이러한 예측과 실제 결과 간의 차이를 계산하여 이를 최소화하는 방향으로 가중치를 조정하며 학습됩니다. 이 과정은 반복적으로 이루어지며, 모델은 예측의 정확도가 높아지도록 계속해서 학습하게 됩니다.\\n\\n이렇게 학습된 모델은 새로운 데이터가 입력되었을 때, 해당 데이터의 패턴이나 관계를 예측하거나 분류할 수 있는 능력을 갖추게 됩니다. 이러한 학습 과정을 통해 인공지능 모델은 더욱 정확하고 효율적으로 작업을 수행할 수 있도록 개선됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 33, 'total_tokens': 428, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CqHDAI2Ih14BkS6ZaH9h7YW6wCOsj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d040e0e4-ce03-48be-815b-9f78e6cc9a4f-0', usage_metadata={'input_tokens': 33, 'output_tokens': 395, 'total_tokens': 428, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수가 하나일 경우에는 예외적으로 딕셔너리 형태가 아니더라도 허용된다.\n",
    "chain.invoke(\"인공지능 모델의 학습 원리\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0232213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate.from_template(\"{topic}에 대해 {how} 설명해주세요.\")\n",
    "\n",
    "model2 = ChatOpenAI()\n",
    "\n",
    "chain2 = prompt2 | model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04139135",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = {\"topic\" : \"인공지능 모델의 학습 원리\", \"how\" : \"간단하게\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2c53a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고 이를 처리하여 원하는 결과를 출력하는 과정을 말합니다. 모델은 처음에는 초기 설정된 일련의 파라미터를 가지고 있고, 이를 기반으로 데이터를 반복적으로 학습하여 최적의 파라미터 값을 찾아내는 과정을 거칩니다.\\n\\n학습 과정은 일반적으로 손실 함수를 통해 모델의 성능을 평가하고 이를 최소화하기 위해 파라미터를 조정하는 과정을 반복하여 진행됩니다. 이 과정을 통해 모델은 데이터의 패턴과 관련된 정보를 습득하고, 새로운 데이터에 대해 정확한 결과를 예측할 수 있게 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 228, 'prompt_tokens': 35, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CqHAus7XfDhXx2N07cTsD2aiS7PN4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5c9a6464-e0cc-41c0-b8e4-13d61343c22d-0', usage_metadata={'input_tokens': 35, 'output_tokens': 228, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b85984",
   "metadata": {},
   "source": [
    "### 출력 파서(Output Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "409fd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de65ac",
   "metadata": {},
   "source": [
    "Chain에 출력 파서를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "963e7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fc0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 입력으로 사용하여 모델 내의 매개변수를 조정함으로써 데이터의 패턴이나 관계를 학습하는 과정입니다. \\n\\n먼저, 모델은 입력된 데이터를 받아들이고, 이 데이터를 처리하여 출력을 생성합니다. 이 출력은 실제 정답 또는 원하는 결과와 비교되어 오차를 계산합니다. 이 오차를 최소화하기 위해 모델 내의 매개변수를 조정하여 예측값을 실제 값에 가깝게 만드는 것이 학습의 목표입니다.\\n\\n모델은 학습 데이터를 반복적으로 사용하여 매개변수를 조정하며 학습하게 됩니다. 이 과정을 통해 모델은 데이터의 패턴을 파악하고, 새로운 데이터에 대한 예측을 수행할 수 있게 됩니다. 이렇게 모델은 데이터를 효율적으로 처리하고 문제를 해결하는 인공지능 시스템으로 발전하게 됩니다. \\n\\n요약하면, 인공지능 모델의 학습은 데이터를 이용하여 매개변수를 조정하고 오차를 최소화하는 과정으로, 모델이 입력된 데이터의 패턴을 학습하여 문제를 해결하는 능력을 향상시키는 것입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\" : \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)\n",
    "\n",
    "# OutputParser를 사용하지 않으면 AIMessage라는 객체에 담겨서 응답이 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e7d7ed",
   "metadata": {},
   "source": [
    "### 템플릿을 변경하여 적용\n",
    "- 아래의 프롬프트 내용을 얼마든지 변경하여 테스트 해볼 수 있습니다.\n",
    "- `model_name` 역시 변경하여 테스트가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8635748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석\n",
    "\"\"\"\n",
    "# {{ }} 중괄호를 2개 쓰면 input_variables로 잡히지 않는다.\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "531c7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bbd5702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  Customer: Hi, could I see the menu, please?\n",
      "  Waiter: Of course! Here you go.\n",
      "  Customer: Thank you. I’d like to order the grilled salmon with a side of roasted vegetables.\n",
      "  Waiter: That’s a great choice! Would you like anything to drink?\n",
      "  Customer: Yes, I’ll have a glass of white wine, please.\n",
      "  Waiter: Sure, I’ll bring that right out for you. Anything else?\n",
      "  Customer: No, that'll be all for now. Thank you.\n",
      "\n",
      "- 한글 해석:\n",
      "  고객: 안녕하세요, 메뉴판 좀 볼 수 있을까요?\n",
      "  웨이터: 물론입니다! 여기 있습니다.\n",
      "  고객: 감사합니다. 구운 연어와 구운 채소 사이드를 주문하겠습니다.\n",
      "  웨이터: 좋은 선택이네요! 음료는 무엇을 드시겠어요?\n",
      "  고객: 네, 화이트 와인 한 잔 주세요.\n",
      "  웨이터: 알겠습니다, 곧 가져다 드리겠습니다. 더 필요하신 것 있으세요?\n",
      "  고객: 아니요, 이걸로 충분합니다. 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "print(chain.invoke({\"question\" : \"저는 식당에 가서 음식을 주문하고 싶어요.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fd65df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  - Customer: Hi, I'd like to order a large pepperoni pizza with extra cheese, please.\n",
      "  - Employee: Sure! Would you like any sides or drinks with that?\n",
      "  - Customer: Yes, can I have an order of garlic bread and two cans of Coke?\n",
      "  - Employee: Absolutely. Will that be for delivery or pick-up?\n",
      "  - Customer: Delivery, please. How long will it take?\n",
      "  - Employee: It should take about 30-45 minutes. May I have your address, please?\n",
      "  - Customer: Sure, it's 123 Elm Street, Apartment 4B.\n",
      "  - Employee: Great! Your total comes to $27.50. We accept cash, credit, or debit. How would you like to pay?\n",
      "  - Customer: I’ll pay with my credit card.\n",
      "  - Employee: Perfect. We’ll process the payment when the delivery arrives. Thank you for ordering with us!\n",
      "\n",
      "- 한글 해석:\n",
      "  - 고객: 안녕하세요, 대형 페퍼로니 피자에 치즈를 추가로 더 넣어서 하나 주문하겠습니다.\n",
      "  - 직원: 네, 사이드 메뉴나 음료도 추가로 주문하시겠어요?\n",
      "  - 고객: 네, 마늘빵 하나와 콜라 두 캔도 주세요.\n",
      "  - 직원: 알겠습니다. 배달로 할까요, 아니면 픽업으로 하시겠어요?\n",
      "  - 고객: 배달로 해주세요. 얼마나 걸리나요?\n",
      "  - 직원: 대략 30-45분 정도 걸립니다. 주소를 알려주시겠어요?\n",
      "  - 고객: 네, 123 엘름 스트리트, 아파트 4B입니다.\n",
      "  - 직원: 좋습니다! 총 금액은 27.50달러입니다. 현금, 신용카드, 데빗 카드 모두 사용 가능합니다. 어떻게 결제하시겠어요?\n",
      "  - 고객: 신용카드로 할게요.\n",
      "  - 직원: 완벽합니다. 배달 시 결제 진행하겠습니다. 저희 피자집을 이용해 주셔서 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "# 이번에는 question을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "print(chain.invoke({\"question\" : \"미국에서 피자 주문\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
